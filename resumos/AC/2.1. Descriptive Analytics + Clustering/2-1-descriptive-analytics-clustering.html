<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="UTF-8">

  <link rel="icon" href="" type="image/png" sizes="16x16"/>
  <link rel="canonical" href="samuuuh.github.io/resumos/AC/2.1.%20Descriptive%20Analytics%20+%20Clustering/2-1-descriptive-analytics-clustering" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Descriptive Analyticsgoals• Describe/summarize or finding structure on what we have observed• Data summarization and visualization (e.g. PCA) can be seen as ...">
  <meta property="og:site_name" content="Knowledge Tree">

  <link rel="stylesheet" href="/knowledge-tree/assets/css/main.css">

  
  <meta property="og:description" content="Descriptive Analyticsgoals• Describe/summarize or finding structure on what we have observed• Data summarization and visualization (e.g. PCA) can be seen as ..."/>
  

  
  <meta property="og:title" content="Descriptive Analytics + Clustering">
  <meta property="og:type" content="article">
  

  
  <meta property="article:published_time" content="2022-02-19T13:44:00+00:00">
  <meta property="article:author" content="samuuuh.github.io/">
  

  <meta property="og:url" content="samuuuh.github.io/resumos/AC/2.1.%20Descriptive%20Analytics%20+%20Clustering/2-1-descriptive-analytics-clustering" />

  

  <title>
    
      Descriptive Analytics + Clustering &mdash; Knowledge Tree
    
  </title>
</head>

  
  <body>
    <nav>
    <div>
        <a class="header-title" href="/knowledge-tree/"><b>Knowledge Tree</b></a>
        <a class="header-link" href="/knowledge-tree/about">About</a>
        <a class="header-link" href="https://github.com/Samuuuh/knowledge-tree">Github</a>
    </div>
</nav>


    <main class="main-content">
      <article>
  <div>
    <h1>Descriptive Analytics + Clustering</h1>
    <time datetime="2022-02-19T13:43:06+00:00">
      Last updated on February 19, 2022
      
    </time>
  </div>

  <div id="notes-entry-container">
    <content>
      <h1 id="descriptive-analytics">Descriptive Analytics</h1>
<h4 id="goals">goals</h4>
<p>• Describe/summarize or finding structure on what we have observed<br />
• Data summarization and visualization (e.g. PCA) can be seen as simple forms of descriptive analytics<br />
• However, most frequently descriptive modeling is associated with clustering</p>

<h2 id="similarity-measures">Similarity Measures</h2>
<h3 id="how-to-measure-similarity-between-objects">How to measure similarity between objects?</h3>
<p>The notion of similarity is strongly related with the notion of<br />
distance between observations. It can be measured as the oposite of the distance.
Proximity refers to a similarity or dissimilarity.</p>

<h3 id="similarity-measure">Similarity measure</h3>
<p>• Numerical measure of how alike two data objects are.<br />
• Is higher when objects are more alike.<br />
• Often falls in the range [0, 1]</p>

<h3 id="dissimilarity-measure">Dissimilarity measure</h3>
<p>• Numerical measure of how different two data objects are<br />
• Lower when objects are more alike<br />
• Minimum dissimilarity is often 0 Upper limit varies</p>

<p>Dissimilarity measure can be expressed by a distance metric. 
Distance metrics d have some well-known properties.</p>

<h4 id="euclidian-distance">Euclidian Distance</h4>
<h4 id="manhattan-distance">Manhattan Distance</h4>
<h4 id="minkowski-distance">Minkowski Distance</h4>

<p>More examples:</p>
<ul>
  <li>Canberra distance</li>
  <li>Jaccard Coefficients</li>
  <li>Cosine similarity</li>
</ul>

<p>Still, several problems may arise that may distort the notion of<br />
distance:<br />
• different scales of variables<br />
• different importance of variables<br />
• different types of data (e.g. both numeric and categorical variables)</p>

<h4 id="heterogeneous-distance-functions">Heterogeneous Distance Functions</h4>
<h4 id="general-coefficient-of-similarity">General Coefficient of Similarity</h4>

<h1 id="clustering">Clustering</h1>
<h4 id="goals-1">Goals</h4>
<p>Obtain the “natural” grouping of a set of data - i.e. find some structure on the data set<br />
	• The key issue on clustering is the notion of similarity<br />
	• Observations on the same group are supposed to share some properties, i.e. being similar<br />
	• Most methods use the information on the distances among observations in a data set to decide on the natural groupings of the cases<br />
Provide some abstraction of the found groups (e.g. a representation of their main features; a prototype for each group; etc.), gain novel insights of data</p>

<h4 id="applications">Applications</h4>
<p><strong>Biology</strong> 
	• describe spatial and temporal communities of organisms<br />
	• group genes or proteins that have similar functionality<br />
<strong>Business and Marketing</strong><br />
	• describe different market segments from a set of potetential clients<br />
	• group stocks with similar price fluctuations<br />
<strong>Web Mining</strong><br />
	• find groups of related documents for information retrieval<br />
	• find communities in social networks<br />
	• build recommender systems</p>

<h3 id="main-types-of-clustering">Main Types of Clustering</h3>
<p>Partitional
	- Divide the observations in k partitions according to some criterion</p>

<p>Hierarchical
	- generate a hierarchy of groups, from 1 to n groups, where n is the number of lines in the data set</p>

<p>Agglomerative
	- generate a hierarchy from bottom to top (from n to 1 group)</p>

<p>Divisive
	- Create a hierarchy in a top down way (from 1 to n groups)</p>

<h4 id="clustering-partitional-methods">Clustering Partitional Methods</h4>
<p>Goal: Partition the given set of data into k groups by either minimizing<br />
or maximizing a pre-specified criterion</p>

<p>Some key issues:<br />
	• The user needs to select the number of groups<br />
	• The number of possible divisions of n cases into k groups can grow fast!</p>

<p>Some important properties<br />
	• Cluster compactness<br />
		• how similar are cases within the same cluster<br />
	• Cluster separation<br />
		• how far is the cluster from the other clusters<br />
	• The goal is to minimize intra-cluster distance and maximize inter-cluster distances.<br />
	• A clustering solution assigns all the objects to a cluster<br />
		• hard clustering: an object belongs to a single cluster<br />
		• fuzzy clustering: each object has a probability associated to belong  to each cluster</p>

<h5 id="k-means">k-Means</h5>
<p>It is a partition-based method that obtains k groups of a data set k-means algorithm.
• Initialize the centers of the k groups to a set of randomly chosen observations</p>

<p>• Repeat<br />
	• Allocate each observation to the group whose center is nearest<br />
	• Re-calculate the center of each group</p>

<p>• Until the groups are stable, i.e. there is no significant decrease or there is an increase on the minimize criterion h(C)</p>

<p>Some observations:<br />
	• It uses the squared Euclidean distance as criterion<br />
	• Maximizes inter-cluster dissimilarity<br />
Advantages:<br />
	• Fast algorithm that scales well<br />
	• Stochastic approach that frequently works well. It tends to identify local minima.<br />
Disadvantages:<br />
	• It does not ensure an optimal clustering<br />
	• We may obtain different solutions with different starting points<br />
	• The initial guess of k for the number of clusters, maybe away from the real optimal value of k .</p>

<h3 id="clutering-validation">Clutering Validation</h3>
<p>How to validate/evaluate/compare the results obtained by some<br />
clustering method?<br />
	• Is the found group structure random?<br />
	• What is the “correct” number of groups?<br />
	• How to evaluate the result of a clustering algorithm when we do<br />
	not have information on the number of groups in the data set?<br />
	• How to compare the results obtained by different methods when<br />
	outside information on the number of groups exists?<br />
	• How to compare alternative solutions (e.g. obtained using different<br />
	clustering algorithms)</p>

<h4 id="supervised">Supervised</h4>
<p>Compare the obtained clustering (grouping) with the<br />
external information that we have available</p>

<h4 id="unsupervised">Unsupervised</h4>
<p>Try to measure the quality of the clustering without<br />
any information on the “ideal” structure of the data.</p>
<ul>
  <li>Cohesion coefficients - determine how compacts/cohesive are the<br />
members of a group</li>
  <li>Separation coefficients - determine how different are the members<br />
of different groups</li>
</ul>

<h4 id="silhouette-coefficient">Silhouette Coefficient</h4>
<p>Popular coefficient that incorporates both the notions of cohesion<br />
and separation. The coefficient takes values between −1 and 1.</p>

<p>Example: iris data set silhouette coefficients si with k = 3 clusters<br />
• Large si (almost 1) means that they are very well clustered.<br />
• Small si (around 0) means that they lie between two clusters.<br />
• Negative si means that they are probably placed in the wrong cluster.<br />
• The closer average silhouette to 1, the better.</p>

<h3 id="best-number-of-clusters">Best Number of Clusters</h3>
<p>• An inappropriate choice of k can result in a clustering with poor<br />
performance.<br />
• What happens if we select a k that is too high? What if the k is too low?<br />
• Ideally, you should have some a priori knowledge on the real structure of the data.<br />
• If no a priori value is known start with √n/2 as a rule of thumb,<br />
where n is the number of attributes.</p>

<p>For several possible number of clusters k:<br />
• Calculate the average silhouette coefficient value and choose the<br />
k that yields to the highest value</p>

<h4 id="elbow-method">Elbow Method</h4>
<p>Calculate the within-cluster SSE, also called distortion, and<br />
choose the k so that adding another cluster doesn’t yield to a<br />
much smaller SSE</p>

<h3 id="other-clustering-partitional-methods">Other Clustering Partitional Methods</h3>
<h4 id="pam-partitioning-around-medoids">PAM (Partitioning Around Medoids)</h4>
<p>• It searches for the k representative objects (the medoids) among<br />
the cases in the given data set.<br />
• As with k-means each observation is allocated to the nearest<br />
medoid.<br />
• Is more robust to the presence of outliers because it uses original<br />
objects as centroids instead of averages that may be subject to<br />
the effects of outliers.<br />
• Moreover, it uses a more robust measure of the clustering quality:<br />
L1 − norm, which is based on absolute error instead of the<br />
squared error used in k-means</p>

<h4 id="clara-clustering-large-applications">CLARA (Clustering Large Applications)</h4>
<p>The PAM algorithm has several advantages in terms of robustness<br />
when compared to k-means.</p>

<p>However, these advantages come at the price of aditional<br />
computational complexity that may be too much for very large data<br />
sets.
• CLARA tries to solve these efficiency problems<br />
• It does that by using sampling, i.e. working on parts of the data set<br />
instead of the full data set</p>

<h5 id="algorithm">Algorithm</h5>
<p>Repeat n times the following:<br />
	• Draw a random sample of size m<br />
	• Apply PAM to this random sample to obtain k centroids<br />
	• Allocate the full set of observations to one of these centroids<br />
	• Calculate sum of dissimilarities of the resulting clustering (as in PAM)<br />
Return as result the clustering of the n repetitions that got lowest sum of dissimilarities</p>

<h4 id="dbscan-density-based-spatial-clustering-of-applications-with-noise">DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</h4>
<p>• The density of a single observation is estimated by the number of<br />
observations that are within a certain radius (a parameter of the<br />
method)<br />
• Based on this idea observations are classified as:<br />
• core points: if the number of observations within its radius are above<br />
a certain threshold<br />
• border points: if the number of observations within their radius does<br />
not reach the threshold but they are within the radius of a core point<br />
• noise points: they do not have enough observations within their<br />
radius, nor are they sufficiently close to any core point</p>

<h5 id="dbscan-algorithm">DBSCAN Algorithm</h5>
<p>• Classify each observation in one of the three possible alternatives<br />
• Eliminate the noise points from the formation of the groups<br />
• All core points that are within a certain distance of each other are<br />
allocated to the same group<br />
• Each border point is allocated to the group of the nearest core point</p>

<p>Note that this method does not require the user to specify the<br />
number of groups.<br />
But, you need to specify the radius (ε) and the minimum number<br />
of points (MinPts)</p>

<h5 id="advantages">Advantages</h5>
<p>• Can handle clusters with different shapes and sizes<br />
• Resistant to noise</p>

<h5 id="disadvantages">Disadvantages</h5>
<p>• Varying densities<br />
• High-dimensional data</p>

<h2 id="hierarchical-clustering">Hierarchical Clustering</h2>
<h4 id="goals-2">Goals</h4>
<p>• Obtain a hierarchy of groups, where each level represents a possible solution with x groups. It is up to the user to select the solution he wants.<br />
• A dendogram can be used for visualization</p>

<h4 id="agglomerative-methods---bottom-up">Agglomerative Methods - bottom-up</h4>
<p>• Start with as many groups as there are cases<br />
• On each upper level a pair of groups is merged into a single group<br />
• The chosen pair is formed by the groups that are more similar</p>

<h4 id="divisive-methods---top-down-much-less-used">Divisive Methods - top-down (much less used)</h4>
<p>• Start with a single group<br />
• On each level select a group to be split in two<br />
• The selected group is the one with smallest uniformity</p>

<p>Some proximity measures for the merging/splitting step</p>
<ul>
  <li>single link</li>
  <li>complete link</li>
  <li>average link</li>
</ul>

<p>Other methods also exist (e.g. distance between the centroids, Ward’s<br />
method that uses SSE).</p>

<h3 id="agglomerative-methods">Agglomerative methods</h3>
<h4 id="algorithm-1">Algorithm</h4>
<p>• Compute the proximity matrix<br />
• Let each data point be a cluster<br />
• Repeat<br />
	• Merge the two closest clusters<br />
	• Update the proximity matrix<br />
• Until only a single cluster remains</p>

<h4 id="different-proximity-measures-yield-to-different-types-of-clusters">Different proximity measures yield to different types of clusters</h4>
<p>Single-link
	• can handle non-elliptical shapes<br />
	• uses a local merge citerion<br />
	• distant parts of the cluster and the clusters’ overall structure are not taken into account</p>

<p>Complete-link<br />
	• biased towards globular clusters<br />
	• uses a non-local merge citerion<br />
	• chooses the pair of clusters whose merge has the smallest diameter<br />
	• the similarity of two clusters is the similarity of their most dissimilar members<br />
	• sensitive to noise/outliers</p>

<p>Average-link<br />
	• it is a compromise between single and complete link</p>

<h3 id="divisive-methods">Divisive Methods</h3>
<h4 id="algorithm-2">Algorithm</h4>
<p>• Compute the proximity matrix<br />
• Start with a single cluster that contains all data points<br />
• Repeat<br />
	• choose the cluster with the largest diameter, i.e. largest dissimilarity between any two of its points<br />
	• select the data point with largest average dissimilarity to the other<br />
	members in that cluster<br />
	• re-allocate the data points to either the cluster of this selected point or the “old” cluster (represented by its center), depending on which one is nearest<br />
• Until each data point constitutes a cluster</p>

<h2 id="wrap-up">Wrap Up</h2>
<p>We can compare clustering methods</p>

<h4 id="algorithm-3">Algorithm</h4>
<p>• complexity and scalability<br />
• similarity measures that can be employed<br />
• robustness to noise<br />
• it is able to find clusters on sub-spaces<br />
• different runs lead to different results<br />
• it is incremental</p>

<h4 id="data">Data</h4>
<p>• it is able to handle different types of data (continuous, categorical,<br />
binary)?<br />
• is there dependency on the order of data points?</p>

<h4 id="domain">Domain</h4>
<p>• does the algorithm finds the number of clusters, or needs it as input?<br />
• how many parameters are necessary?<br />
• what is the required domain knowledge for that?</p>

<h4 id="results">Results</h4>
<p>• shape of clusters that is able to find<br />
• interpretability</p>

    </content>

    <side style="font-size: 0.9em">
      <div class="notes">
        <h3 style="margin-bottom: 1em">Notes mentioning this note</h3>
        
        <div style="display: grid; grid-gap: 1em; grid-template-columns: repeat(1fr);">
        
          <div class="backlink-box">
          <a class="internal-link" href="/knowledge-tree/resumos/AC/AC/ac">Aprendizagem Computacional</a><br>
          <div style="font-size: 0.9em">Resumos da cadeira</div>
          </div>
        
        </div>
        
      </div>
      <div class="graph-viz">
        <h3 style="margin-bottom: 1em">Graph Visualization</h3>
        <style>
  .links line {
    stroke: #ccc;
    opacity: 0.5;
  }

  .nodes circle {
    cursor: pointer;
    fill: #8b88e6;
    transition: all 0.15s ease-out;
  }

  .text text {
    cursor: pointer;
    fill: #333;
    text-shadow: -1px -1px 0 #fafafabb, 1px -1px 0 #fafafabb, -1px 1px 0 #fafafabb, 1px 1px 0 #fafafabb;
  }

  .nodes [active],
  .text [active] {
    cursor: pointer;
    fill: black;
  }

  .inactive {
    opacity: 0.1;
    transition: all 0.15s ease-out;
  }

  #graph-wrapper {
    background: #fcfcfc;
    border-radius: 4px;
    height: auto;
  }
</style>

<script src="https://cdnjs.cloudflare.com/ajax/libs/d3/5.16.0/d3.min.js"
  integrity="sha512-FHsFVKQ/T1KWJDGSbrUhTJyS1ph3eRrxI228ND0EGaEp6v4a/vGwPWd3Dtd/+9cI7ccofZvl/wulICEurHN1pg=="
  crossorigin="anonymous"></script>

<div id="graph-wrapper">
  <script>
    const MINIMAL_NODE_SIZE = 8;
    const MAX_NODE_SIZE = 12;
    const ACTIVE_RADIUS_FACTOR = 1.5;
    const STROKE = 1;
    const FONT_SIZE = 16;
    const TICKS = 200;
    const FONT_BASELINE = 40;
    const MAX_LABEL_LENGTH = 50;

    const graphData = {"edges":[{"source":"503179796958532336743230207621597515898","target":"1422108377848304020"},{"source":"100072086790617209837265","target":"38041"},{"source":"103841823815487875","target":"27613844020"},{"source":"240589227765099673052794226274910629357","target":"2402776049557"},{"source":"240589227765099673052794226274910629357","target":"81676889533246026119639"},{"source":"240589227765099673052794226274910629357","target":"105853271995781485577129644"},{"source":"240589227765099673052794226274910629357","target":"18206486889979855229696720616166476532701018412"},{"source":"240589227765099673052794226274910629357","target":"19548904114439035294623638491398769279229399"},{"source":"240589227765099673052794226274910629357","target":"7853092808745256997741119377796504708"},{"source":"240589227765099673052794226274910629357","target":"2782927863386519"},{"source":"240589227765099673052794226274910629357","target":"7850043983027514073448502100"},{"source":"240589227765099673052794226274910629357","target":"3241122110819881232318764"},{"source":"240589227765099673052794226274910629357","target":"5495051139013699250083799"},{"source":"240589227765099673052794226274910629357","target":"65443548425971875856684"},{"source":"240589227765099673052794226274910629357","target":"6421157057681797349145782253"},{"source":"46378530244815725","target":"240589227765099673052794226274910629357"},{"source":"774714518649319842117578546054867522169132704794","target":"103841823815487875"},{"source":"774714518649319842117578546054867522169132704794","target":"1680077656773453826"},{"source":"774714518649319842117578546054867522169132704794","target":"447698746565831359475675571306886394"},{"source":"774714518649319842117578546054867522169132704794","target":"1851849395087745244631"},{"source":"774714518649319842117578546054867522169132704794","target":"174414388749633151336036"},{"source":"774714518649319842117578546054867522169132704794","target":"3896682460950866925"},{"source":"46378530244815725","target":"774714518649319842117578546054867522169132704794"},{"source":"774714518649319842117578546054867522169132704794","target":"71684638065172"},{"source":"46378530244815725","target":"1632202199179734376687545757396595518803233444679072"},{"source":"50183515407140165401415593961866212395148222461086","target":"297117087099758275271869396"},{"source":"50183515407140165401415593961866212395148222461086","target":"143768490085477247"},{"source":"50183515407140165401415593961866212395148222461086","target":"2119742351888060458029509408534670102650"},{"source":"50183515407140165401415593961866212395148222461086","target":"49670930463710165929681420635052"},{"source":"50183515407140165401415593961866212395148222461086","target":"8377370676197544955211194395789671980339971808048"},{"source":"50183515407140165401415593961866212395148222461086","target":"5500055021409855647479244329548649272482"},{"source":"50183515407140165401415593961866212395148222461086","target":"133540821863415617892879786549633158"},{"source":"50183515407140165401415593961866212395148222461086","target":"1516445552606797852005007732405178305066454090157728370000968386"},{"source":"46378530244815725","target":"50183515407140165401415593961866212395148222461086"}],"nodes":[{"id":"93602086757531175064909553","path":"/knowledge-tree/conceitos/Algorithms/Breath%20First%20Search/breath-first-search","label":"Breath first search"},{"id":"2964338397953191999125233","path":"/knowledge-tree/conceitos/Algorithms/Depth%20First%20Search/depth-first-search","label":"Depth first search"},{"id":"63022295962788201453","path":"/knowledge-tree/conceitos/Databases/Data%20Retrieval/data-retrieval","label":"Data retrieval"},{"id":"6925473830595409991896469767149","path":"/knowledge-tree/conceitos/Databases/Information%20Retrieval/information-retrieval","label":"Information retrieval"},{"id":"39788157","path":"/knowledge-tree/conceitos/Databases/NoSQL/nosql","label":"Nosql"},{"id":"37245","path":"/knowledge-tree/conceitos/Databases/SQL/sql","label":"Sql"},{"id":"1422108377848304020","path":"/knowledge-tree/conceitos/Networks/Asynchronous/asynchronous","label":"Asynchronous"},{"id":"33773422613162","path":"/knowledge-tree/conceitos/Networks/Byzantine/byzantine","label":"Byzantine"},{"id":"1248953862480574","path":"/knowledge-tree/conceitos/Networks/CAP%20Theorem/cap-theorem","label":"Cap theorem"},{"id":"595361","path":"/knowledge-tree/conceitos/Networks/CRDT/crdt","label":"Crdt"},{"id":"20980633","path":"/knowledge-tree/conceitos/Networks/Chord/chord","label":"Chord"},{"id":"180758507946934573733853352570660","path":"/knowledge-tree/conceitos/Networks/Distributed%20Hash%20Tables/distributed-hash-tables","label":"Distributed hash tables"},{"id":"196617406559747521982777238352564","path":"/knowledge-tree/conceitos/Networks/Epidemic%20Broadcat%20Trees/epidemic-broadcat-trees","label":"Epidemic broadcat trees"},{"id":"118364582846116905859515843","path":"/knowledge-tree/conceitos/Networks/Event-driven%20Server/event-driven-server","label":"Event Driven server"},{"id":"100072086790617209837265","path":"/knowledge-tree/conceitos/Networks/Gangster%20Paradox/gangster-paradox","label":"Gangster paradox"},{"id":"1305755994574","path":"/knowledge-tree/conceitos/Networks/Gnutella/gnutella","label":"Gnutella"},{"id":"28147445","path":"/knowledge-tree/conceitos/Networks/Graph/graph","label":"Graph"},{"id":"5346763475629440007514921644","path":"/knowledge-tree/conceitos/Networks/Interval%20Tree%20Clocks/interval-tree-clocks","label":"Interval tree clocks"},{"id":"1589861734498","path":"/knowledge-tree/conceitos/Networks/Kademlia/kademlia","label":"Kademlia"},{"id":"132141122442877141061782","path":"/knowledge-tree/conceitos/Networks/Linearizability/linearizability","label":"Linearizability"},{"id":"6417667107358961591817717861","path":"/knowledge-tree/conceitos/Networks/Media%20Access%20Control/media-access-control","label":"Media access control"},{"id":"23476356606711367982773281694029108615542100","path":"/knowledge-tree/conceitos/Networks/Message%20Authentication%20Code%20(MAC)/message-authentication-code-mac","label":"Message authentication code (mac)"},{"id":"503179796958532336743230207621597515898","path":"/knowledge-tree/conceitos/Networks/Message%20Oriented%20Middleware/message-oriented-middleware","label":"Message oriented middleware"},{"id":"11266535818559391234661965445002205","path":"/knowledge-tree/conceitos/Networks/Network%20Time%20Protocol%20(NTP)/network-time-protocol-ntp","label":"Network time protocol (ntp)"},{"id":"44825854","path":"/knowledge-tree/conceitos/Networks/Qorum/qorum","label":"Qorum"},{"id":"35904","path":"/knowledge-tree/conceitos/Networks/RPC/rpc","label":"Rpc"},{"id":"136004183879632219828","path":"/knowledge-tree/conceitos/Networks/Spanning%20Trees/spanning-trees","label":"Spanning trees"},{"id":"105891339425632660","path":"/knowledge-tree/conceitos/Networks/Synchronous/synchronous","label":"Synchronous"},{"id":"38041","path":"/knowledge-tree/conceitos/Networks/TCP/tcp","label":"Tcp"},{"id":"64200629008","path":"/knowledge-tree/conceitos/Networks/Threads/threads","label":"Threads"},{"id":"39373","path":"/knowledge-tree/conceitos/Networks/UDP/udp","label":"Udp"},{"id":"4132761509213563564","path":"/knowledge-tree/conceitos/Networks/Vector%20Clocks/vector-clocks","label":"Vector clocks"},{"id":"27613844020","path":"/knowledge-tree/conceitos/Web/Cookies/cookies","label":"Cookies"},{"id":"10321053344592847707750121767318446802220","path":"/knowledge-tree/conceitos/Web/Cross-Origin%20Resource%20Sharing/cross-origin-resource-sharing","label":"Cross Origin resource sharing"},{"id":"221215993544965438794685914937440718","path":"/knowledge-tree/conceitos/Web/Cross-Site%20Request%20Forgery/cross-site-request-forgery","label":"Cross Site request forgery"},{"id":"3483726243430623321687796","path":"/knowledge-tree/conceitos/Web/Frames%20and%20iFrames/frames-and-iframes","label":"Frames and iframes"},{"id":"1397113493381","path":"/knowledge-tree/conceitos/Web/HTTP%20Auth/http-auth","label":"Http auth"},{"id":"6255301569195718647962674","path":"/knowledge-tree/conceitos/Web/Same-Origin%20Policy/same-origin-policy","label":"Same Origin policy"},{"id":"6280954365573304766971756","path":"/knowledge-tree/conceitos/Web/Session%20Hijacking/session-hijacking","label":"Session hijacking"},{"id":"43804","path":"/knowledge-tree/conceitos/Web/XSS/xss","label":"Xss"},{"id":"46378530244815725","path":"/knowledge-tree/index/index","label":"Content List"},{"id":"2402776049557","path":"/knowledge-tree/resumos/AC/1.1.%20Introdution/1-1-introdution","label":"Untitled"},{"id":"81676889533246026119639","path":"/knowledge-tree/resumos/AC/1.2.%20Data%20Preparation/1-2-data-preparation","label":"Data Preparation"},{"id":"105853271995781485577129644","path":"/knowledge-tree/resumos/AC/1.3.%20Data%20Understanding/1-3-data-understanding","label":"Data Understanding"},{"id":"391640284630317801447218589253556416661780951","path":"/knowledge-tree/resumos/AC/1.4.%20Advanced%20Topics%20-%20Data%20Preparation/1-4-advanced-topics-data-preparation","label":"Advanced Topics - Data Preparation"},{"id":"18206486889979855229696720616166476532701018412","path":"/knowledge-tree/resumos/AC/2.1.%20Descriptive%20Analytics%20+%20Clustering/2-1-descriptive-analytics-clustering","label":"Descriptive Analytics + Clustering"},{"id":"210690132241943189195520856119340","path":"/knowledge-tree/resumos/AC/2.2.%20Frequent%20Pattern%20Mining%20-%20Association%20Rules/2-2-frequent-pattern-mining-association-rules","label":"Frequent Pattern Mining"},{"id":"19548904114439035294623638491398769279229399","path":"/knowledge-tree/resumos/AC/3.1.%20Introduction%20to%20Classification/3-1-introduction-to-classification","label":"Introduction to Classification"},{"id":"7853092808745256997741119377796504708","path":"/knowledge-tree/resumos/AC/3.2.%20Classification%20Algorithms/3-2-classification-algorithms","label":"Classification ALgorithms"},{"id":"2782927863386519","path":"/knowledge-tree/resumos/AC/3.3.%20Regression/3-3-regression","label":"Regression"},{"id":"7850043983027514073448502100","path":"/knowledge-tree/resumos/AC/3.4.%20Introduction%20to%20Recommender%20Systems/3-4-introduction-to-recommender-systems","label":"Recommender Systems"},{"id":"3241122110819881232318764","path":"/knowledge-tree/resumos/AC/3.5.%20Ensemble%20Learning/3-5-ensemble-learning","label":"Ensemble Learning"},{"id":"5495051139013699250083799","path":"/knowledge-tree/resumos/AC/4.1.%20Outlier%20Detection/4-1-outlier-detection","label":"Outlier Detection"},{"id":"65443548425971875856684","path":"/knowledge-tree/resumos/AC/4.2.%20ANN%20+%20Introduction%20to%20Deep%20Learning/4-2-ann-introduction-to-deep-learning","label":"ANN + Deep Learning"},{"id":"6421157057681797349145782253","path":"/knowledge-tree/resumos/AC/4.3.%20Metalearning%20&%20AutoML/4-3-metalearning-automl","label":"Metalearning & AutoML"},{"id":"240589227765099673052794226274910629357","path":"/knowledge-tree/resumos/AC/AC/ac","label":"Aprendizagem Computacional"},{"id":"103841823815487875","path":"/knowledge-tree/resumos/FSI/1.%20Web/1-web","label":"Segurança Web"},{"id":"1680077656773453826","path":"/knowledge-tree/resumos/FSI/2.%20Criptografia/2-criptografia","label":"Criptografia"},{"id":"447698746565831359475675571306886394","path":"/knowledge-tree/resumos/FSI/3.%20PK%20Infrastructure/3-pk-infrastructure","label":"Public-Key Infrastructure"},{"id":"1851849395087745244631","path":"/knowledge-tree/resumos/FSI/4.%20Authentication/4-authentication","label":"Authentication"},{"id":"174414388749633151336036","path":"/knowledge-tree/resumos/FSI/5.%20Redes/5-redes","label":"Segurança de Redes"},{"id":"3896682460950866925","path":"/knowledge-tree/resumos/FSI/6.%20TLS/6-tls","label":"TLS and Signal"},{"id":"774714518649319842117578546054867522169132704794","path":"/knowledge-tree/resumos/FSI/FSI/fsi","label":"Fundamentos de Segurança Informática"},{"id":"71684638065172","path":"/knowledge-tree/resumos/FSI/Perguntas%20FSI/perguntas-fsi","label":"Perguntas"},{"id":"1632202199179734376687545757396595518803233444679072","path":"/knowledge-tree/resumos/PRI/PRI/pri","label":"Processamento e Recuperação de Informação"},{"id":"1385730979894442211642858409180597843489748945","path":"/knowledge-tree/resumos/SDLE/10.%20Quorum%20Consensus%20Replicated%20ADT/10-quorum-consensus-replicated-adt","label":"10. quorum consensus replicated adt"},{"id":"297117087099758275271869396","path":"/knowledge-tree/resumos/SDLE/11.%20Byzantine%20Quorums/11-byzantine-quorums","label":"11. byzantine quorums"},{"id":"2452250852148947176341154290704886726148708359198638","path":"/knowledge-tree/resumos/SDLE/12.%20Practical%20Byzantine%20Fault-Tolerance/12-practical-byzantine-fault-tolerance","label":"12. practical byzantine fault Tolerance"},{"id":"143768490085477247","path":"/knowledge-tree/resumos/SDLE/13.%20Blockchain/13-blockchain","label":"13. blockchain"},{"id":"2119742351888060458029509408534670102650","path":"/knowledge-tree/resumos/SDLE/2.%20Message%20Oriented%20Middleware/2-message-oriented-middleware","label":"2. message oriented middleware"},{"id":"49670930463710165929681420635052","path":"/knowledge-tree/resumos/SDLE/3.%20Processing%20and%20Scaling/3-processing-and-scaling","label":"3. processing and scaling"},{"id":"8377370676197544955211194395789671980339971808048","path":"/knowledge-tree/resumos/SDLE/4.%20Replication%20and%20Consistency%20Models/4-replication-and-consistency-models","label":"4. replication and consistency models"},{"id":"7856802203877937602475915419792883785110654260","path":"/knowledge-tree/resumos/SDLE/5.%20Scalable%20Distributed%20Topologies/5-scalable-distributed-topologies","label":"5. scalable distributed topologies"},{"id":"5500055021409855647479244329548649272482","path":"/knowledge-tree/resumos/SDLE/6.%20System%20Design%20for%20Large%20Scale/6-system-design-for-large-scale","label":"6. system design for large scale"},{"id":"133540821863415617892879786549633158","path":"/knowledge-tree/resumos/SDLE/7.%20Physical%20and%20Logical%20Time/7-physical-and-logical-time","label":"7. physical and logical time"},{"id":"1516445552606797852005007732405178305066454090157728370000968386","path":"/knowledge-tree/resumos/SDLE/8.%20High%20Availability%20under%20Eventual%20Consistency/8-high-availability-under-eventual-consistency","label":"8. high availability under eventual consistency"},{"id":"77564326098429129869107156","path":"/knowledge-tree/resumos/SDLE/9.%20Quorums%20Consensus/9-quorums-consensus","label":"9. quorums consensus"},{"id":"50183515407140165401415593961866212395148222461086","path":"/knowledge-tree/resumos/SDLE/SDLE/sdle","label":"Sistemas Distribuídos em Larga Escala"}]}
    let nodesData = graphData.nodes;
    let linksData = graphData.edges;

    const nodeSize = {};

    const updateNodeSize = () => {
      nodesData.forEach((el) => {
        let weight =
          3 *
          Math.sqrt(
            linksData.filter((l) => l.source.id === el.id || l.target.id === el.id)
              .length + 1
          );
        if (weight < MINIMAL_NODE_SIZE) {
          weight = MINIMAL_NODE_SIZE;
        } else if (weight > MAX_NODE_SIZE) {
          weight = MAX_NODE_SIZE;
        }
        nodeSize[el.id] = weight;
      });
    };

    const onClick = (d) => {
      window.location = d.path
    };

    const onMouseover = function (d) {
      const relatedNodesSet = new Set();
      linksData
        .filter((n) => n.target.id == d.id || n.source.id == d.id)
        .forEach((n) => {
          relatedNodesSet.add(n.target.id);
          relatedNodesSet.add(n.source.id);
        });

      node.attr("class", (node_d) => {
        if (node_d.id !== d.id && !relatedNodesSet.has(node_d.id)) {
          return "inactive";
        }
        return "";
      });

      link.attr("class", (link_d) => {
        if (link_d.source.id !== d.id && link_d.target.id !== d.id) {
          return "inactive";
        }
        return "";
      });

      link.attr("stroke-width", (link_d) => {
        if (link_d.source.id === d.id || link_d.target.id === d.id) {
          return STROKE * 4;
        }
        return STROKE;
      });
      text.attr("class", (text_d) => {
        if (text_d.id !== d.id && !relatedNodesSet.has(text_d.id)) {
          return "inactive";
        }
        return "";
      });
    };

    const onMouseout = function (d) {
      node.attr("class", "");
      link.attr("class", "");
      text.attr("class", "");
      link.attr("stroke-width", STROKE);
    };

    const sameNodes = (previous, next) => {
      if (next.length !== previous.length) {
        return false;
      }

      const map = new Map();
      for (const node of previous) {
        map.set(node.id, node.label);
      }

      for (const node of next) {
        const found = map.get(node.id);
        if (!found || found !== node.title) {
          return false;
        }
      }

      return true;
    };

    const sameEdges = (previous, next) => {
      if (next.length !== previous.length) {
        return false;
      }

      const set = new Set();
      for (const edge of previous) {
        set.add(`${edge.source.id}-${edge.target.id}`);
      }

      for (const edge of next) {
        if (!set.has(`${edge.source.id}-${edge.target.id}`)) {
          return false;
        }
      }

      return true;
    };

    const graphWrapper = document.getElementById('graph-wrapper')
    const element = document.createElementNS("http://www.w3.org/2000/svg", "svg");
    element.setAttribute("width", graphWrapper.getBoundingClientRect().width);
    element.setAttribute("height", window.innerHeight * 0.8);
    graphWrapper.appendChild(element);

    const reportWindowSize = () => {
      element.setAttribute("width", window.innerWidth);
      element.setAttribute("height", window.innerHeight);
    };

    window.onresize = reportWindowSize;

    const svg = d3.select("svg");
    const width = Number(svg.attr("width"));
    const height = Number(svg.attr("height"));
    let zoomLevel = 1;

    const simulation = d3
      .forceSimulation(nodesData)
      .force("forceX", d3.forceX().x(width / 2))
      .force("forceY", d3.forceY().y(height / 2))
      .force("charge", d3.forceManyBody())
      .force(
        "link",
        d3
          .forceLink(linksData)
          .id((d) => d.id)
          .distance(70)
      )
      .force("center", d3.forceCenter(width / 2, height / 2))
      .force("collision", d3.forceCollide().radius(80))
      .stop();

    const g = svg.append("g");
    let link = g.append("g").attr("class", "links").selectAll(".link");
    let node = g.append("g").attr("class", "nodes").selectAll(".node");
    let text = g.append("g").attr("class", "text").selectAll(".text");

    const resize = () => {
      if (d3.event) {
        const scale = d3.event.transform;
        zoomLevel = scale.k;
        g.attr("transform", scale);
      }

      const zoomOrKeep = (value) => (zoomLevel >= 1 ? value / zoomLevel : value);

      const font = Math.max(Math.round(zoomOrKeep(FONT_SIZE)), 1);

      text.attr("font-size", (d) => font);
      text.attr("y", (d) => d.y - zoomOrKeep(FONT_BASELINE) + 8);
      link.attr("stroke-width", zoomOrKeep(STROKE));
      node.attr("r", (d) => {
        return zoomOrKeep(nodeSize[d.id]);
      });
      svg
        .selectAll("circle")
        .filter((_d, i, nodes) => d3.select(nodes[i]).attr("active"))
        .attr("r", (d) => zoomOrKeep(ACTIVE_RADIUS_FACTOR * nodeSize[d.id]));
    };

    const ticked = () => {
      node.attr("cx", (d) => d.x).attr("cy", (d) => d.y);
      text
        .attr("x", (d) => d.x)
        .attr("y", (d) => d.y - (FONT_BASELINE - nodeSize[d.id]) / zoomLevel);
      link
        .attr("x1", (d) => d.source.x)
        .attr("y1", (d) => d.source.y)
        .attr("x2", (d) => d.target.x)
        .attr("y2", (d) => d.target.y);
    };

    const restart = () => {
      updateNodeSize();
      node = node.data(nodesData, (d) => d.id);
      node.exit().remove();
      node = node
        .enter()
        .append("circle")
        .attr("r", (d) => {
          return nodeSize[d.id];
        })
        .on("click", onClick)
        .on("mouseover", onMouseover)
        .on("mouseout", onMouseout)
        .merge(node);

      link = link.data(linksData, (d) => `${d.source.id}-${d.target.id}`);
      link.exit().remove();
      link = link.enter().append("line").attr("stroke-width", STROKE).merge(link);

      text = text.data(nodesData, (d) => d.label);
      text.exit().remove();
      text = text
        .enter()
        .append("text")
        .text((d) => shorten(d.label.replace(/_*/g, ""), MAX_LABEL_LENGTH))
        .attr("font-size", `${FONT_SIZE}px`)
        .attr("text-anchor", "middle")
        .attr("alignment-baseline", "central")
        .on("click", onClick)
        .on("mouseover", onMouseover)
        .on("mouseout", onMouseout)
        .merge(text);

      node.attr("active", (d) => isCurrentPath(d.path) ? true : null);
      text.attr("active", (d) => isCurrentPath(d.path) ? true : null);

      simulation.nodes(nodesData);
      simulation.force("link").links(linksData);
      simulation.alpha(1).restart();
      simulation.stop();

      for (let i = 0; i < TICKS; i++) {
        simulation.tick();
      }

      ticked();
    };

    const zoomHandler = d3.zoom().scaleExtent([0.2, 3]).on("zoom", resize);

    zoomHandler(svg);
    restart();

    function isCurrentPath(notePath) {
      return window.location.pathname.includes(notePath)
    }

    function shorten(str, maxLen, separator = ' ') {
      if (str.length <= maxLen) return str;
      return str.substr(0, str.lastIndexOf(separator, maxLen)) + '...';
    }
  </script>
</div>

      </div>
    </side>
  </div>
</article>
    </main>

    <footer>
      <p style="text-align: center;">Wow, you just found a wild footer!</p>

    </footer>
  </body>
</html>
