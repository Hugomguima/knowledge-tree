---
title: "Data Preparation"
---

# Data Preparation
The majority of time taken by any data mining project is spent in data preparation
- e.g. importing, manipulating, cleaning, transforming, augmenting

## Data
### What is data?
Collection of data objects (cases) and their attributes (features)
• Attribute: a property or characteristic of an object
• date, country, temperature, precipitation
• Object: described by a collection of attributes
• It can be structured (e.g. data table) or non-structured (e.g. text)
• It can have non-dependency or dependency between objects (e.g. time, space)

### Types of data sets
1. **Nondependency-oriented data**
	• the cases do not have any dependencies between them
	• examples: simple data tables, text
2. **Dependency-oriented data**
	• implicit or explicit relationships between cases
	• examples: time series, discrete sequences, spatialtemporal data, network and graph data.
3. **Categorical / Qualitative Attributes**
	• Nominal: there is no relationship between the values  
	• name, gender, patient id  
	• Ordinal: there is an order between the values, but no mathematical  
	operation can be performed on them  
	• size ∈ {small, medium, large}
4. **Numeric / Quantitative Attributes**  
	• Discrete: finite or countably infinite set of values for which  
	differences are meaningful  
	• temperatures in Celsius, calendar dates, event duration in minutes  
	• Continuous: inifinite set of values that represent the absolute  
	numbers  
	• number of visits to the hospital, distance, income

### Characteristics
- Dimensionality (i.e. number of attributes)  
	• high dimensional data brings several challenges  
- Sparsity  
	• presence attributes  
- Resolution  
	• patterns depend on the scale  
- Size  
	• type of analysis may depend on size of data

### Data Preparation
• Typically, data analysis tasks use source data sets stored in  
tabular format.  
	• datasets are bi-dimensional structures (e.g. table)  
	
• How can we import data from different sources and / or formats?  
• How can we easily manipulate the data?  
• How can we transform the data?

## Data Wrangling
Process of transforming and mapping data from one “raw” data form into another format appropriate for analytics.  

- Main steps  
	• discovering  
	• structuring  
	• cleaning  
	• enriching  
	• validating  
	• publishing  

• Goal: attain quality and useful data.

## Data Quality
• The raw format of real data is usually widely variable as values may be missing, insconsistent across different data sources, erroneous.  
• Poor data quality poses several challenges to the effective data analysis  

Example:  
	• A classification model for predicting a client’s loan risks is built  
	using poor data  
		• credit-worthy candidates are denied loans  
		• loans are given to individuals that default

---
• What are the kinds of data quality problems?  
• How can we detect problems with the data?  
• What can we do about these problems?  

Examples of data quality problems:  
	• Noise and outliers  
	• Missing values  
	• Duplicate data  
	• Incosistent or incorrect data

### Noise
• Noise may refer to irrelevant or useless information
• It can be caused by incorrect or distorted measurements
• It can also be caused by the proper variability of the domain

### Outliers 
Outliers are data objects with characteristics that are considerably different than most of the other data objects in the data set .

• Case 1: outliers are noise that interferes with data analysis (eg: 130◦C value for air temperature)
• Case 2: outliers are the goal of our analysis (eg: credit card fraud, intrusion detection)

### Missing Values
#### Problems
Missing Completely at Random (MCAR)  
	• missing value is independent of observed and unobserved data  
	• there is nothing systematic about it  
	• e.g. a lab value because a lab sample was processed improperly  
Missing at Random (MAR)  
	• missing value is related to observed data, not to unobserved data.  
	• there may be something systematic about it  
	• e.g. missing income value may depend on the age  
Missing Not at Random (MNAR)  
	• missing value is related to unobserved data of the variable itself  
	• informative / non-ignorable missingness  
	• e.g. a person did not entered his/her weight in a survey

#### Solutions:  
• remove observations with missing values, i.e. consider only complete cases  
• critical if there are meany observations with missing values  
• ignore missining values in the analytical phase  
• use methods that are inherently designed to work robustly with missing values  
• make estimates to fill the missing values - imputation  
• the most common value of the attribute (e.g. mean, mode); based on other(s) attribute(s); more sophisticated methods  
• it might introduce bias in data and affect the results

### Duplicates
• Data set may include data objects that are duplicates, or almost duplicates of one another  
	• Major issue when merging data from heterogeneous sources  

Examples:  
	• Same person with multiple email addresses  
	
It is necessary a process of dealing with duplicate data issues  
	• When should duplicate data not be removed?

### Inconsistent or Incorrect Data
• This the hardest type of data quality issues to detect  
• It may depend on expert domain knowlege  

Examples:  
	• 4/11/2000: Nov. 4th or April, 11th?  
	• author name in a publication (e.g. John Smith, J. Smith, Smith J.)  
	• a city called Shanghai in the United States